---
title: "10x Genomics scATAC-seq QC"
author: 
 - Lucas Graybuck
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  html_document:
    code_folding: hide
    df_print: paged
    self_contained: true
params:
  in_pre: NULL
  in_frag: NULL
  in_meta: NULL
  genome: NULL
  refs: "all"
  window_sizes: "all"
  out_dir: NULL
---

<a id="contents"></a>

## Contents

#### [Data Processing](#data_processing)
- [Session Preparation](#session_preparation)
- [Load References](#load_refs)
- [Read Metadata](#assemble_meta)
- [ArchR QC Analysis](#archr)
- [Output metadata](#meta_out)
- [Generate Matrices](#mats)

#### [QC Metrics](#qc_stats)
- [Cell Barcode QC](#barcode_stats)
- [Fragment Metrics](#fragment_stats)
- [Saturation Metrics](#saturation_stats)
- [10x Genomics Metrics](#tenx_stats)

#### [QC Plots](#qc_plots)
- [UMI Saturation Plot](#saturation_plot)
- [Signal Saturation Plot](#signal_plot)
- [Fragment Width Plot](#width_plot)
- [All Cell Histograms](#all_hist_plot)
- [Reads vs altius_frac Plot](#reads_altius_frac_plot)
- [Reads vs peaks_frac Plot](#reads_peaks_frac_plot)
- [peaks_frac vs tss_frac Plot](#peaks_frac_tss_frac_plot)
- [RIP vs RITSS Plot](#rip_ritss_plot)
- [Filtered Histograms](#filtered_hist_plot)

[Write QC JSON](#json_out)

#### [Session Info](#session_info)

<a id="data_processing"></a>

## Data Processing

<a id="session_preparation"></a>

### Session Preparation

#### Load libraries:
```{r Load Libraries}
start_time <- Sys.time()

quiet_library <- function(...) {
  suppressPackageStartupMessages(library(...))
}
quiet_library(ATAComb)
quiet_library(H5weaver)
quiet_library(Matrix)
quiet_library(S4Vectors)
quiet_library(ggplot2)
quiet_library(cowplot)
quiet_library(jsonlite)
quiet_library(purrr)
options(stringsAsFactors = FALSE)
```

Declaring start
```{r Declare start}
stm("Starting scATAC-seq assembly")
```

#### Argument parsing
```{r Parse arguments}
if(is.null(params$in_pre)) {
  in_pre <- system.file("testdata/preprocessed", package = "ATAComb")
  in_frag <- system.file("testdata/outs/fragments.tsv.gz", package = "ATAComb")
  in_meta <- system.file("testdata/batch_qc/X055_X055-AP0C1W1_filtered_metadata.csv.gz", package = "ATAComb")
  genome <- "hg38"
  refs <- "all"
  window_sizes <- "all"
  out_dir <- tempdir()
} else {
  in_pre <- params$in_pre
  in_frag <- params$in_frag
  in_meta <- params$in_meta
  genome <- params$genome
  refs <- params$refs
  window_sizes <- params$window_sizes
  out_dir <- params$out_dir
}

# Check Genome
if(!genome %in% c("hg38","hg19")) {
  stm(paste0("Genome must be 'hg38' or 'hg19'. Genome provided: ", genome))
  stop()
}

if(is.null(refs)) {
  refs <- "all"
}

if(is.null(window_sizes)) {
  window_sizes <- "all"
}

stm(paste0("IN  preprocessed dir          : ", in_pre))
stm(paste0("IN  filtered_fragments.tsv.gz : ", in_frag))
stm(paste0("IN  filtered_metadata.csv.gz  : ", in_meta))
stm(paste0("IN  Genome                    : ", genome))
stm(paste0("IN  References                : ", refs))
stm(paste0("IN  Window Sizes              : ", window_sizes))
stm(paste0("OUT Directory                 : ", out_dir))
```

```{r}
in_pre <- "/mnt/x070-multiome/hashing-pipeline-testing/PB1051W10/atac_preprocessed/"
in_frag <- "/mnt/x070-multiome/hashing-pipeline-testing/atac_frag_merged/X070-P1_PB1051W10_fragments.tsv.gz"
in_meta <- "/mnt/x070-multiome/hashing-pipeline-testing/atac_meta_merged/X070-P1_PB1051W10_filtered_metadata.csv.gz"
genome <- "hg38"
refs <- "all"
window_sizes <- "all"
out_dir <- "/mnt/x070-multiome/hashing-pipeline-testing/PB1051W10/atac_qc/"
```

#### Input Parameters
```{r Print Arguments}
print(c(
  paste0("IN  preprocessed dir          : ", in_pre),
  paste0("IN  filtered_fragments.tsv.gz : ", in_frag),
  paste0("IN  filtered_metadata.csv.gz  : ", in_meta),
  paste0("IN  Genome                    : ", genome),
  paste0("IN  References                : ", refs),
  paste0("IN  Window Sizes              : ", window_sizes),
  paste0("OUT Directory                 : ", out_dir)
))
```

#### Set ArchR parameters
```{r setup archr}
quiet_library(ArchR)

stm("Setting ArchR parameters")
set.seed(3030)

available_cores <- parallel::detectCores()
stm(paste0("Using ",available_cores, " threads"))

addArchRThreads(available_cores, force = TRUE)
addArchRGenome(genome)
```

#### Check Input Files
```{r Check Inputs}
if(!dir.exists(in_pre)) {
  stm(paste0("ERROR: Cannot find IN preprocessed dir:", in_pre))
  stop()
}
if(!file.exists(in_frag)) {
  stm(paste0("ERROR: Cannot find IN filtered_fragments.tsv.gz:", in_frag))
  stop()
} 
if(!file.exists(in_meta)) {
  stm(paste0("ERROR: Cannot find IN filtered_metadata.csv.gz:", in_meta))
  stop()
}

in_prefix <- in_pre
in_sample <- sub("_fragments.tsv.gz", "", basename(in_frag))
in_sample <- sub("_filtered", "", in_sample)

stm(paste0("Using Sample Name:", in_sample))

out_prefix <- file.path(out_dir, paste0(in_sample, "_"))

stm(paste0("Using Output Prefix:", out_prefix))
```

#### Check reference overlap files
```{r}
reference_files <- list.files(system.file("reference", package = "ATAComb"), 
                              pattern = paste0(genome, ".+gr.rds"),
                              full.names = TRUE)
reference_names <- sub(paste0(".+",genome,"_"),"",reference_files)
reference_names <- sub("_gr.rds","",reference_names)

stm(paste(c("Available references:", reference_names), collapse = " "))

feature_mat_files <- list.files(in_pre, pattern = "sparse_matrix.tsv.gz", full.names = TRUE)
feature_mat_names <- sub("_sparse_matrix.tsv.gz","", basename(feature_mat_files))
feature_mat_names <- sub("[^_]+_", "", feature_mat_names)
stm(paste(c("Available reference matrices:", feature_mat_names), collapse = " "))

matching_refs <- intersect(reference_names, feature_mat_names)
stm(paste(c("Preprocessed reference data:", matching_refs), collapse = " "))

if(length(matching_refs) == 0) {
  stop("Preprocessed reference datasets do not match available references")
} else {
  reference_files <- reference_files[match(matching_refs, reference_names)]
  reference_names <- matching_refs
  feature_mat_files <- feature_mat_files[match(matching_refs, feature_mat_names)]
  feature_mat_names <- matching_refs
}

if(refs == "all") {
  stm("Using all matching references")
} else {
  split_refs <- unlist(strsplit(refs, split = ","))
  
  # Check for matching references
  good_refs <- intersect(split_refs, reference_names)
  
  # Stop if no matches
  if(length(good_refs) == 0) {
    stop(paste("No references match", refs))
  }
  
  combined_good_refs <- paste(good_refs, collapse = " ")
  stm(paste0("Selected references: ", combined_good_refs))
  
  reference_files <- reference_files[match(good_refs, reference_names)]
  reference_names <- good_refs
  
  feature_mat_files <- feature_mat_files[match(good_refs, feature_mat_names)]
  feature_mat_names <- good_refs
  
  # Warn about mismatches
  bad_refs <- setdiff(split_refs, reference_names)
  if(length(bad_refs) > 0) {
    bad_refs <- paste(bad_refs, collapse = ",")
    stm(paste0("WARNING: Reference input(s) ",bad_refs," do not match available references. Skipping."))
  }
}

```

#### Check window sizes
```{r}
window_mat_files <- list.files(in_pre, pattern = "window.+counts.tsv.gz", full.names = TRUE)
window_mat_names <- sub("_counts.tsv.gz","",basename(window_mat_files))
window_mat_names <- sub("[^_]+_", "", window_mat_names)
stm(paste(c("Available window matrices:", window_mat_names), collapse = " "))

if(window_sizes[1] == "all") {
  stm("Using all Available window matrices")
  use_windows <- window_mat_names
} else {
  split_windows <- unlist(strsplit(window_sizes, split = ","))
  
  # Check for matching references
  good_windows <- intersect(split_windows, window_mat_names)
  
  # Stop if no matches
  if(length(good_windows) == 0) {
    stop(paste("No window matrices match", window_sizes))
  }
  
  combined_good_windows <- paste(good_windows, collapse = " ")
  stm(paste0("Selected window matrices: ", good_windows))
  
  window_mat_names <- good_windows
  window_mat_files <- window_mat_files[match(good_windows, window_mat_names)]
  
  # Warn about mismatches
  bad_windows <- setdiff(split_windows, window_mat_names)
  if(length(bad_windows) > 0) {
    bad_windows <- paste(bad_windows, collapse = ",")
    stm(paste0("WARNING: Window input(s) ",bad_windows," do not match available matrices. Skipping."))
  }
}
```

#### Create out directory if missing
```{r Create Out Dir}
if(!dir.exists(out_dir)) {
  stm(paste0("Creating Output Directory: ",out_dir))
  dir.create(out_dir, 
             recursive = TRUE)
}
```

[Return to Contents](#contents)

<a id="load_refs"></a>

#### Load Reference Datasets
```{r Load references}
stm(paste("Loading reference region sets for", genome))

reference_datasets <- map(reference_files,
                          readRDS)

gr_to_df <- function(gr) {
  df <- data.frame(seqnames = seqnames(gr),
                   start = start(gr),
                   end = end(gr),
                   strand = strand(gr))
  
  mc <- as.data.frame(mcols(gr)@listData)
  
  if(nrow(mc) == nrow(df)) {
    cbind(df, mc)
  } else {
    df
  }
  
}

reference_datasets <- map(reference_datasets, gr_to_df)

names(reference_datasets) <- reference_names

reference_meta <- map(seq_along(reference_datasets),
                      function(x) {
                        dt <- reference_datasets[[x]]
                        reference_name = reference_names[x]
                        meta <- data.frame(name = paste0(dt$seqnames, "_", dt$start, "_", dt$end),
                                           id = paste0(genome, "_", reference_name, "_", 1:nrow(dt)))
                        if(ncol(dt) > 5) {
                          meta <- cbind(meta, dt[6:ncol(dt)])
                        }
                        
                        as.list(meta)
                      })

names(reference_meta) <- reference_names
```

[Return to Contents](#contents)

<a id="assemble_meta"></a>

### Load Metadata

```{r}
stm(paste0("Reading metadata from ", in_meta))

filtered_meta <- read.csv(in_meta)
```

[Return to Contents](#contents)

<a id="archr"></a>

### ArchR QC analysis

#### Create Arrow file
```{r}
stm(paste0("ArchR: Building ArrowFile from ",in_frag))
valid_barcodes <- list(bcs = filtered_meta$barcodes)
names(valid_barcodes) <- in_sample
valid_barcodes <- SimpleList(valid_barcodes)

ArrowFile <- createArrowFiles(inputFiles = in_frag,
                              sampleNames = in_sample,
                              validBarcodes = valid_barcodes,
                              filterFrags = 500,
                              filterTSS = 0,
                              maxFrags = 1e6,
                              force = TRUE)

stm(paste0("ArchR: ArrowFile generated at ", ArrowFile))

```

#### Score and filter doublets
```{r}
stm("ArchR: Scoring doublets")
doublet_scores <- addDoubletScores(input = ArrowFile,
                                   force = TRUE)

proj <- ArchRProject(ArrowFiles = ArrowFile,
                     copyArrows = TRUE)

archr_meta <- getCellColData(proj)
archr_meta <- as.data.frame(archr_meta)

proj_ArrowFile <- getArrowFiles(proj)
stm(paste0("ArchR: Project ArrowFile located at ", proj_ArrowFile))
```


```{r}
# Store unfiltered names for later
archr_names <- getCellNames(proj)
archr_barcodes <- sub(".+#","",archr_names)

# Check for doublet scoring
# This will be FALSE in the case of small test datasets
if(min(doublet_scores[[1]]$doubletEnrich) >= 1) {
  stm("WARNING: DOUBLET SCORING FAILED.")
}

# Get counts for reporting
n_total <- nrow(filtered_meta)

stm(paste0("ArchR: Total barcodes = ", n_total))

proj2 <- filterDoublets(proj)
filtered_names <- getCellNames(proj2)

archr_meta <- archr_meta %>%
  dplyr::mutate(singlet = archr_names %in% filtered_names)

n_singlets <- sum(archr_meta$singlet)

stm(paste0("ArchR: Singlet barcodes = ", n_singlets))

n_doublets <-  sum(!archr_meta$singlet)
stm(paste0("ArchR: Doublet barcodes = ", n_doublets))

# Match order to archr file
rownames(filtered_meta) <- filtered_meta$barcodes
filtered_meta <- filtered_meta[archr_barcodes,]

# Add additional ArchR metadata to filtered_meta
filtered_meta$DoubletScore <- archr_meta[["DoubletScore"]]
filtered_meta$DoubletEnrichment <- archr_meta[["DoubletEnrichment"]]
filtered_meta$singlet <- archr_meta[["singlet"]]
filtered_meta$TSSEnrichment <- archr_meta[["TSSEnrichment"]]
```

#### Save Archr project and shift arrow to output directory
```{r}
ArrowFile <- getArrowFiles(proj)

out_arrow <- paste0(out_prefix, "archr.arrow")

stm(paste0("Saving .arrow to ", out_arrow))
file.copy(ArrowFile, out_arrow)
```

Resolve metadata discrepancies
```{r}
stm("Resolving metadata discrepencies")
proj_meta <- getCellColData(proj)
h5_ls <- h5ls(out_arrow)

h5_MetaNames <- h5_ls[h5_ls$group == "/Metadata",]

# Add missing metadata
additional_meta <- setdiff(names(filtered_meta), h5_MetaNames$name)
if(length(additional_meta) > 0) {
  for(meta_col in additional_meta) {
    h5write(filtered_meta[[meta_col]],
            out_arrow,
            paste0("/Metadata/",meta_col))
  }
}
```

#### Clean up ArchR in memory
```{r}
rm(proj)
```


[Return to Contents](#contents)

<a id="write_meta"></a>

#### Write unfiltered and filtered metadata
```{r}
filtered_meta_out <- paste0(out_prefix, "filtered_metadata.csv.gz")
stm(paste("Writing filtered metadata to", filtered_meta_out))
fwrite(filtered_meta, filtered_meta_out)
```

[Return to Contents](#contents)

<a id="mats"></a>

## Build Feature Matrices

#### Read overlaps and output results
```{r Region Matrices}
stm("Building reference matrices")

obs_list <- as.list(filtered_meta[,names(filtered_meta) != "barcodes"])

walk(seq_along(feature_mat_files),
     function(x) {
       mat_file <- feature_mat_files[x]
       mat_name <- feature_mat_names[x]
       
       n_features <- nrow(reference_datasets[[mat_name]])
       
       stm(paste("Building",mat_name,"matrix"))
       
       dt <- fread(mat_file,
                   header = FALSE,
                   col.names = c("barcodes",
                                 "i",
                                 "x"),
                   colClasses = list("character" = 1,
                                     "integer" = c(2,3)))
       
       dt <- dt[barcodes %in% filtered_meta$barcodes]
       barcode_counts <- table(dt$barcodes)
       new_barcodes <- filtered_meta$barcodes[match(names(barcode_counts), filtered_meta$barcodes)]
       
       mat_list <- list(matrix = list(barcodes = new_barcodes,
                                      data = dt$x,
                                      indices = dt$i - 1,
                                      indptr = c(0, cumsum(barcode_counts)),
                                      shape = c(n_features, nrow(filtered_meta)),
                                      features = reference_meta[[mat_name]],
                                      observations = obs_list))
       rm(dt)
       
       out_file <- paste0(out_prefix, mat_name, ".h5")
       stm(paste("Writing .h5 file to:", out_file))
       write_h5_list(mat_list,
                     out_file,
                     overwrite = TRUE)
       
       rm(mat_list)
     })
```

[Return to Contents](#contents)

### Window count matrices
```{r}
stm("Building window matrices")
window_sizes <- as.numeric(sub("window_([0-9]+)k","\\1",window_mat_names)) * 1000

window_offsets <- map(window_sizes,
                      function(size) {
                        read_chrom_sizes(genome = genome,
                                         window_size = size)
                      })
names(window_offsets) <- window_mat_names

window_metas <- map(seq_along(window_offsets),
                    function(x) {
                      offsets <- window_offsets[[x]]
                      window_mat_name <- window_mat_names[x]
                      window_size <- window_sizes[x]
                      
                      region_bed <- window_index_to_bed(1:sum(offsets$n_windows),
                                                        offsets,
                                                        window_size = window_size)
                      region_bed$start <- as.character(format(region_bed$start, scientific = FALSE))
                      region_bed$end <- as.character(format(region_bed$end, scientific = FALSE))
                      list(name = gsub(" +","",paste(region_bed$chr, region_bed$start, region_bed$end, sep = "_")),
                           id = paste0(genome, "_", window_mat_name, "_", 1:nrow(region_bed)))
                      
                    })
names(window_metas) <- window_mat_names
```

#### Generate window matrices
```{r Window Matrices}
walk(seq_along(window_mat_files),
     function(x) {
       window_mat_file <- window_mat_files[x]
       window_mat_name <- window_mat_names[x]
       window_size <- window_sizes[x]
       
       window_offsets <- window_offsets[[window_mat_name]]
       window_meta <- window_metas[[window_mat_name]]
       
       stm(paste("Building",window_mat_name,"matrix"))
       
       dt <- fread(window_mat_file,
                   header = FALSE,
                   col.names = c("barcodes",
                                 "chr",
                                 "chr_i",
                                 "x"),
                   colClasses = list("character" = c(1,2),
                                     "integer" = c(3,4)))
       
       dt <- dt[barcodes %in% filtered_meta$barcodes]
       offsets <- window_offsets[,c("chr","offset")]
       
       dt <- dt[offsets, on = "chr"]
       dt$i <- dt$chr_i + dt$offset
       dt <- dt[!is.na(barcodes)]
       dt <- setorder(dt, barcodes, i)
       
       barcode_counts <- table(dt$barcodes)
       new_barcodes <- filtered_meta$barcodes[match(names(barcode_counts), filtered_meta$barcodes)]
       
       window_list <- list(matrix = list(barcodes = new_barcodes,
                                         data = dt$x,
                                         indices = dt$i - 1,
                                         indptr = c(0, cumsum(barcode_counts)),
                                         shape = c(sum(window_offsets$n_windows),
                                                   nrow(filtered_meta)),
                                         features = window_meta,
                                         observations = obs_list))
       rm(dt)
       
       window_list$matrix$observations <- as.list(filtered_meta)
       
       out_file <- paste0(out_prefix, window_mat_name, ".h5")
       stm(paste("Writing .h5 file to:", out_file))
       write_h5_list(window_list,
                     out_file,
                     overwrite = TRUE)
       
       rm(window_list)
     })
```

[Return to Contents](#contents)

<a id="qc_stats"></a>

### QC Stats

```{r}
qc_list <- list(report_type = "atac_qc",
                report_datetime = as.character(start_time),
                report_uuid = ids::uuid(use_time = TRUE),
                package = "ATAComb",
                package_version = sessionInfo()$otherPkgs$ATAComb$Version)

out_json <- paste0(out_prefix, "atac_qc_metrics.json")
```

[Return to Contents](#contents)

<a id="barcode_stats"></a>

#### Barcode QC Stats
```{r}
barcode_conditions <- list(
  "pass_qc" = rep(TRUE, nrow(filtered_meta)),
  "doublets" = !filtered_meta$singlet,
  "singlets" = filtered_meta$singlet
)

perc_of <- function(x, d) {
  round(sum(x) / d * 100, 2)
}

q_of <- function(x, target, q) {
  vals <- target[x]
  round(quantile(vals, probs = q), 4)
}

barcode_qc_stats <- data.frame(
  metric = c("Barcodes pass QC",
             "Doublets pass QC",
             "Singlets pass QC"),
  count = sapply(barcode_conditions, sum),
  percent = sapply(barcode_conditions, perc_of, nrow(filtered_meta)),
  median_fragments = sapply(barcode_conditions, q_of, filtered_meta$n_fragments, .50),
  median_unique = sapply(barcode_conditions, q_of, filtered_meta$n_unique, .50),
  median_altius_frac = sapply(barcode_conditions, q_of, filtered_meta$altius_frac, .50),
  median_peaks_frac = sapply(barcode_conditions, q_of, filtered_meta$peaks_frac, .50),
  median_tss_frac = sapply(barcode_conditions, q_of, filtered_meta$tss_frac, .50))

qc_list$barcode_qc_stats <- as.list(barcode_qc_stats)
qc_list$barcode_qc_stats$metric <- c("barcodes_gt1k","barcodes_pass_qc","barcodes_fail_qc",
                                     "barcodes_fail_altius_frac","barcodes_fail_peaks_frac","barcodes_fail_tss_frac","barcodes_fail_all")

qc_table(barcode_qc_stats)
```

[Return to Contents](#contents)

<a id="qc_plots"></a>

### QC Plots

<a id="width_plot"></a>

#### Plot Fragment Widths
```{r}
frag_widths_file <- list.files(in_pre, pattern = "_fragment_widths.tsv.gz", full.names = TRUE)

frag_widths <- fread(frag_widths_file,
                     header = FALSE,
                     col.names = c("barcodes", "width", "count"),
                     colClasses = list("character" = 1,
                                       "integer" = c(2,3)))

frag_widths$singlet <- ifelse(frag_widths$barcodes %in% filtered_meta$barcodes[filtered_meta$singlet],
                              "singlet",
                              "doublet")
frag_widths <- frag_widths[, sum(count), by = list(singlet, width)]
names(frag_widths)[3] <- "totals"
frag_widths <- frag_widths[, frac:=totals/sum(totals), by = list(singlet)]
frag_widths <- frag_widths[width <= 750]

out_widths <- paste0(out_prefix, "fragment_width_summary.csv.gz") 

stm(paste("Writing fragment width summary to", out_widths))
fwrite(frag_widths, out_widths)

ggplot(data = frag_widths) +
  geom_line(aes(x = width,
                y = frac,
                group = singlet,
                color = singlet),
            size = 1) +
  xlim(0, 750) +
  facet_grid(rows = vars(singlet)) +
  theme_bw()
```

[Return to Contents](#contents)

<a id="filtered_hist_plot"></a>

#### Filtered QC Histograms
```{r}
cutoffs <- list(altius_frac = 0.5, peaks_frac = 0.2, tss_frac = 0.2)

n_reads_hist <- qc_hist_plot(filtered_meta,
                             column = "n_unique",
                             name_x = "N Unique Fragments per Cell",
                             log_x = TRUE,
                             fill = "dodgerblue",
                             target = 2500,
                             y_max = 1000)
altius_frac_hist <- qc_frac_hist_plot(filtered_meta,
                                      column = "altius_frac",
                                      name_x = "Frac Reads in Altius Index (altius_frac)",
                                      fill = "darkgreen",
                                      target = cutoffs$altius_frac,
                                      y_max = 8000)
peaks_frac_hist <- qc_frac_hist_plot(filtered_meta,
                                     column = "peaks_frac",
                                     name_x = "Frac Reads in Peaks (peaks_frac)",
                                     fill = "mediumorchid3",
                                     target = cutoffs$peaks_frac,
                                     y_max = 5000)
tss_frac_hist <- qc_frac_hist_plot(filtered_meta,
                                   column = "tss_frac",
                                   name_x = "Frac Reads in TSS (tss_frac)",
                                   fill = "orangered",
                                   target = cutoffs$tss_frac,
                                   y_max = 5000)
plot_list <- list(n_reads_hist,
                  altius_frac_hist,
                  peaks_frac_hist,
                  tss_frac_hist)

cowplot::plot_grid(plotlist = plot_list,
                   nrow = 4, ncol = 1)
```

[Return to Contents](#contents)

<a id="json_out"></a>

### Write QC JSON

```{r Save QC JSON}
stm(paste0("Writing JSON to ",out_json))

qc_list_json <- jsonlite::toJSON(qc_list,
                                 auto_unbox = TRUE,
                                 pretty = TRUE)

writeLines(qc_list_json,
           out_json)
```

[Return to Contents](#contents)

<a id="session_info"></a>

## Session Information

```{r Session Info}
sessionInfo()
```

Total time elapsed
```{r Show Time}
end_time <- Sys.time()
diff_time <- end_time - start_time
time_message <- paste0("Elapsed Time: ", 
                       round(diff_time, 3),
                       " ", units(diff_time))
print(time_message)
stm(time_message)
stm("10x ATAC assembly process complete.")
```

[Return to Contents](#contents)
